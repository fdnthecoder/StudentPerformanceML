{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUDENT PERFORMANCES\n",
    "## Machine Learning project\n",
    "## Team: Amadou and Jamie\n",
    "\n",
    "* Analysis of student performances\n",
    "* Features: 33 \n",
    "* Data: 649\n",
    "\n",
    "There are 2 different csv files in the data folder. One (student-port.csv) being the data set of the students that took the portugese language course and another (student-mat.csv) of the students that are taking the math course. There are 382 students that are taking both courses. \n",
    "\n",
    "More information about the dataset is in the data folder, labeled student.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as r\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # It is important in neural networks to scale the date\n",
    "from sklearn.model_selection import train_test_split  # The standard - train/test to prevent overfitting and choose hyperparameters\n",
    "from sklearn.metrics import accuracy_score # \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
      "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
      "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
      "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
      "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
      "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
      "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
      "644     MS   F   19       R     GT3       T     2     3  services     other   \n",
      "645     MS   F   18       U     LE3       T     3     1   teacher  services   \n",
      "646     MS   F   18       U     GT3       T     1     1     other     other   \n",
      "647     MS   M   17       U     LE3       T     3     1  services  services   \n",
      "648     MS   M   18       R     LE3       T     3     2  services     other   \n",
      "\n",
      "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
      "0    ...      4        3      4     1     1      3        4   0  11  11  \n",
      "1    ...      5        3      3     1     1      3        2   9  11  11  \n",
      "2    ...      4        3      2     2     3      3        6  12  13  12  \n",
      "3    ...      3        2      2     1     1      5        0  14  14  14  \n",
      "4    ...      4        3      2     1     2      5        0  11  13  13  \n",
      "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
      "644  ...      5        4      2     1     2      5        4  10  11  10  \n",
      "645  ...      4        3      4     1     1      1        4  15  15  16  \n",
      "646  ...      1        1      1     1     1      5        6  11  12   9  \n",
      "647  ...      2        4      5     3     4      2        6  10  10  10  \n",
      "648  ...      4        4      1     3     4      5        4  10  11  11  \n",
      "\n",
      "[649 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\student-por.csv\",sep=\";\") #read file from different directory\n",
    "print(df1)\n",
    "#df1.to_csv(\"port.csv\") # made in to a csv after being made in to a table - easier to read compared to original excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       7.7\n",
       "1      10.4\n",
       "2      12.3\n",
       "3      14.0\n",
       "4      12.4\n",
       "       ... \n",
       "644    10.3\n",
       "645    15.4\n",
       "646    10.5\n",
       "647    10.0\n",
       "648    10.7\n",
       "Length: 649, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splitting the data accordingly\n",
    "X = df1.iloc[:, :30]\n",
    "y = 0.3 * df1.iloc[:, 30] + 0.3 * df1.iloc[:, 31] + 0.4 * df1.iloc[:, 32]\n",
    "X.dropna()\n",
    "y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixingfile(X):\n",
    "    switch = {0: (\"GP\", \"MS\"), 1: (\"F\", \"M\"), 3: (\"U\", \"R\"), 4: (\"LE3\", \"GT3\"), 5:(\"T\", \"A\"), 15:(\"yes\",\"no\"), 16:(\"yes\",\"no\"),\n",
    "             17:(\"yes\",\"no\"), 18:(\"yes\",\"no\"), 19:(\"yes\",\"no\"), 20:(\"yes\",\"no\"), 21:(\"yes\",\"no\"), 22:(\"yes\",\"no\")}\n",
    "    #ignore = [\"age\", \"Medu\", \"Fedu\",\"Mjob\", \"Fjob\", 'reason', 'guardian','traveltime', 'studytime',\n",
    "    #       'failures']\n",
    "    #print(X.columns)\n",
    "    #print(X.iloc[0,:])\n",
    "    for column in range(len(X.columns)):\n",
    "        if column not in switch:\n",
    "            continue\n",
    "        for i in range(len(X.iloc[:,column])):\n",
    "           #print(X.iloc[i, column] == \"U\",X.iloc[i, column], switch[column])\n",
    "            if X.iloc[i,column] == switch[column][0]:\n",
    "                #print(X.iloc[i, column], switch[column][0])\n",
    "                X.iloc[i,column] = 1\n",
    "            elif X.iloc[i, column] == switch[column][1]:\n",
    "                X.iloc[i,column] = 0\n",
    "    X.drop([\"Mjob\", \"Fjob\", \"reason\", \"guardian\"], axis = 1, inplace=True) #Remove the ones with more than 1 and 0 answers\n",
    "    print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(649, 26)\n"
     ]
    }
   ],
   "source": [
    "X_fixed = fixingfile(X)\n",
    "y = np.array(y) #changed to array to be easier to work with\n",
    "X = np.array(X_fixed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM here on out the markdown split up which model. Add cells according to which mark down. Here is the order\n",
    "## 1. Linear Regression\n",
    "## 2. Neutral Network \n",
    "## 3. SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 649\n"
     ]
    }
   ],
   "source": [
    "N = y.shape[0]\n",
    "print(\"Number of rows:\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = StandardScaler()\n",
    "X_fit= np.array(X_scale.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and test set.  60% training and %40 test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fit, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 2))\n",
    "    for i in range(len(y)):\n",
    "        if y[i] >= 10:\n",
    "            y_vect[i, 0] = 1\n",
    "        else:\n",
    "            y_vect[i, 1] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing training set shape:  (389, 2)\n",
      "Testing testing set shape:  (260, 2)\n"
     ]
    }
   ],
   "source": [
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)\n",
    "print(\"Testing training set shape: \",y_v_train.shape)\n",
    "print(\"Testing testing set shape: \",y_v_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function - depends on whether we want to use it or not\n",
    "def f(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def f_deriv(z):\n",
    "    return f(z) * (1 - f(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y, a_out, z_out):\n",
    "    # delta^(nl) = -(y_i - a_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-a_out) * f_deriv(z_out) \n",
    "\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {} #creating a dictionary i.e. a set of key: value pairs\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1])) #Return “continuous uniform” random floats in the half-open interval [0.0, 1.0). \n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    a = {1: x} # create a dictionary for holding the a values for all levels\n",
    "    z = { } # create a dictionary for holding the z values for all the layers\n",
    "    for l in range(1, len(W) + 1): # for each layer\n",
    "        node_in = a[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l]  # z^(l+1) = W^(l)*a^(l) + b^(l)\n",
    "        a[l+1] = f(z[l+1]) # a^(l+1) = f(z^(l+1))\n",
    "    return a, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train NN without regularization\n",
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored a and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-a[l])) \n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(a^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))# np.newaxis increase the number of dimensions\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/N * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/N * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/N * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rigde_nn(nn_structure, X, y, iter_num=3000, alpha=0.25, hyper = 0.1):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    N = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(N):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored a and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            a, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], a[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-a[l])) \n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(a^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(a[l][:,np.newaxis]))# np.newaxis increase the number of dimensions\n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/N * tri_W[l]) + hyper * W[l]\n",
    "            b[l] += -alpy_testha * (1.0/N * tri_b[l])\n",
    "        # complete they_test average cost calculation\n",
    "        avg_cost = 1.0/N * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(W, b, X, n_layers):\n",
    "    N = X.shape[0]\n",
    "    y = np.zeros((N,))\n",
    "    for i in range(N):\n",
    "        a, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(a[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n",
      "Iteration 1000 of 3000\n",
      "Iteration 2000 of 3000\n"
     ]
    }
   ],
   "source": [
    "nn_structure = [26, 30, 2]\n",
    "    \n",
    "# train the NN\n",
    "W, b, avg_cost_func = train_nn(nn_structure, X_train, y_v_train, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAk0UlEQVR4nO3deXhc9X3v8fd3ZjTaV0uWZXmRF4zZjREECEl8k0CAkpK0eQJJmjQ0LaWFNJenvS1t0rR3ee5Nm5v25l7SAk1IaEtCkoYQQglrWBMabINtbMDGeMHyKnnRZmv/3j/OkTyWJVm2NTNnNJ/X88wz55w5c+Z7PJY++p3fOb9j7o6IiOSvWLYLEBGR7FIQiIjkOQWBiEieUxCIiOQ5BYGISJ5LZLuAk1VbW+tNTU3ZLkNEJKesXr26zd3rxnot54KgqamJVatWZbsMEZGcYmbbx3tNh4ZERPKcgkBEJM8pCERE8pyCQEQkzykIRETynIJARCTPKQhERPJc3gTB7vYj/K+fvcH2/d3ZLkVEJFJy7oKyU7Vy20G++cJW7n5uC1csruWT75rHlWfXUxDPmywUERlT3gTBr18wm0uaavjBqh088PI7/OH9r1BXXsjnrljAp941j/KigmyXKCKSFZZrdyhrbm720x1iYnDIeW7TPu59cRsvbm6jvCjBZy6bz+euWEhNaXKKKhURiQ4zW+3uzWO+lo9BkGrtjkPc9dzbPLZhD2WFCf5wxWJuencTRQXxKfsMEZFsUxBMwqa9nfzNz97k6Tf30VBZxB3XLOXXL5iNmU35Z4mIZNpEQaCe0tCS+nK+9dmL+d7vXUptWSFfeGANN31nJS0HD2e7NBGRtFIQjHLZohk8dOu7+fJ1Z/Py1gNc+XfPc/+vtpNrLScRkclSEIwhHjN+54oFPHH7e2luquaLP17Pbd99lfYj/dkuTURkyikIJjCnuoT7brqEO65ZyuMb9nDd/3uBt/Z2ZrssEZEppSA4gVjMuOV9i/j+719GT/8Qv/EPv+SFt1qzXZaIyJRREEzSRfOreejWd9NYXcxnv72Sh17dme2SRESmhILgJDRWFfPDWy7jkqYabv/BGn60uiXbJYmInDYFwUkqLyrg3s9ezOWLZvAn/7aWn67dle2SREROi4LgFBQn43zrty+meX41f/zDtazadiDbJYmInDIFwSkqKohzz6ebaawq5vf+eRU7DujCMxHJTWkNAjO72sw2mtlmM7tjjNerzezHZrbOzF42s3PTWc9Uqy5N8u3PXszAoPNHD7xK/+BQtksSETlpaQsCM4sD3wCuAc4GPmFmZ49a7S+ANe5+PvAZ4OvpqiddmmpL+Z+/cR6vvnOIv39yU7bLERE5aelsEVwCbHb3Le7eBzwAXD9qnbOBpwHc/U2gyczq01hTWnz4gtl8vHkOdz+/hQ272rNdjojISUlnEDQCO1LmW8JlqdYCvwFgZpcA84E5ozdkZjeb2SozW9XaGs2Lub547dlUFRfwpYfWMzSkcYlEJHekMwjGGr959G/IrwDVZrYG+DzwKjBw3Jvc73H3Zndvrqurm/JCp0JlSQF/ce1ZvPrOIR7WKaUikkPSGQQtwNyU+TnAMb8h3b3D3W9y92UEfQR1wNY01pRWH72wkaWzyvn6028xoI5jEckR6QyClcAZZrbAzJLAjcDDqSuYWVX4GsDvAs+7e0caa0qrWMy4/colbG3rVqtARHJG2oLA3QeA24DHgTeAH7j7BjO7xcxuCVc7C9hgZm8SnF30hXTVkylXnV3P4pll3PfLbdkuRURkUhLp3Li7Pwo8OmrZXSnTLwFnpLOGTDMzPn3pfP7q4Q2saznE+XOqsl2SiMiEdGVxGnx0eSPFBXEeWLnjxCuLiGSZgiANKooK+MBZM3l8/R51GotI5CkI0uTa8xrY393HyxqQTkQiTkGQJivOrCOZiPHU6/uyXYqIyIQUBGlSkkzQPL+al7bsz3YpIiITUhCk0eWLZvDG7g4OdPdluxQRkXEpCNLoskUzAHh5q/oJRCS6FARpdM7sSuIxY/1OjUgqItGlIEijooI4Z8wsY72GphaRCFMQpNk5sytZv7Mddw1NLSLRpCBIs7Maymnr6uPg4f5slyIiMiYFQZotqC0FYGtbd5YrEREZm4IgzZrCINimIBCRiFIQpNnc6hJiBtv2KwhEJJoUBGmWTMRorC7mnQOHs12KiMiYFAQZMKuiiD3tPdkuQ0RkTAqCDKivKGJvh4JARKJJQZABQRD06loCEYkkBUEGzKoo4kj/IB09A9kuRUTkOAqCDKgrLwSgtbM3y5WIiBxPQZABlSUFALQf0dXFIhI9CoIMqCoeDgLdl0BEokdBkAFVJUkADmm8IRGJoLQGgZldbWYbzWyzmd0xxuuVZvZTM1trZhvM7KZ01pMtwy0CBYGIRFHagsDM4sA3gGuAs4FPmNnZo1a7FXjd3S8AVgBfM7NkumrKlorhIFAfgYhEUDpbBJcAm919i7v3AQ8A149ax4FyMzOgDDgATLtzLOMxo6IoQfth9RGISPSkMwgagR0p8y3hslR3AmcBu4DXgC+4+9DoDZnZzWa2ysxWtba2pqvetKooLtBZQyISSekMAhtj2ehLaz8ErAFmA8uAO82s4rg3ud/j7s3u3lxXVzfVdWZEaTLB4b7BbJchInKcdAZBCzA3ZX4OwV/+qW4CHvTAZmArsDSNNWVNSWGcI/0KAhGJnnQGwUrgDDNbEHYA3wg8PGqdd4APAJhZPXAmsCWNNWVNSTJOd++06/4QkWkgka4Nu/uAmd0GPA7EgXvdfYOZ3RK+fhfw34HvmNlrBIeS/szd29JVUzYVFyTY36XOYhGJnrQFAYC7Pwo8OmrZXSnTu4Cr0llDVJTq0JCIRJSuLM6Q4NCQgkBEokdBkCElyQRH+tRHICLRoyDIkJJknMP9g7o5jYhEjoIgQ4qTcdyhd+C46+VERLJKQZAhyXjwT60gEJGoURBkSGEi+KfuUxCISMQoCDKkIGwR9A8qCEQkWhQEGZJUi0BEIkpBkCEjQaAWgYhEjIIgQ4Y7i9UiEJGoURBkSIFaBCISUQqCDClUi0BEIkpBkCHqLBaRqFIQZIhOHxWRqFIQZIhaBCISVQqCDNHpoyISVQqCDNHpoyISVQqCDFGLQESiSkGQIWoRiEhUKQgyJBE3AAYGdWMaEYkWBUGGJGLBP/XAkIJARKIlMd4LZlYzwft63b07DfVMW/FY0CIY0q0qRSRixg0CYDXggI31PjMDuMPd7x9vA2Z2NfB1IA58092/Mur1/wJ8KqWWs4A6dz8w6T3IEYmYDg2JSDSNGwTuvmCiN5pZHfAcMGYQmFkc+AZwJdACrDSzh9399ZTP+Crw1XD9DwO3T8cQAIjFDDMYHFJnsYhEyyn3Ebh7K/BnE6xyCbDZ3be4ex/wAHD9BOt/AvjeqdaTCxIxUx+BiETOaXUWu/tPJ3i5EdiRMt8SLjuOmZUAVwM/Guf1m81slZmtam1tPdVysy4eMwYVBCISMek8a2isvoXxfgt+GPjFeIeF3P0ed2929+a6uropKzDT4qYWgYhEz6SCwMyuMLObwuk6M5uw/yDUAsxNmZ8D7Bpn3RuZ5oeFQC0CEYmmEwaBmf0VQV/An4eLCoB/ncS2VwJnmNkCM0sS/LJ/eIztVwLvA34y2aJzVSIeUxCISORMdProsI8CFwKvALj7LjMrP9Gb3H3AzG4DHic4ffRed99gZreEr9+Vsv0n8uG6hLg6i0UkgiYTBH3u7mbmAGZWOtmNu/ujwKOjlt01av47wHcmu81cloiZTh8VkciZTB/BD8zsbqDKzH4PeAr4p/SWNT2pRSAiUXTCFoG7/28zuxLoAM4EvuzuT6a9smkooc5iEYmgyRwaIvzFr1/+p0ktAhGJohMGgZl1cvz5/+3AKuCP3X1LOgqbjuIxY1BjDYlIxEymRfB3BOf/f5fgIrEbgVnARuBeYEW6iptu4rGYWgQiEjmT6Sy+2t3vdvdOd+9w93uAa939+0B1muubVhIx0zDUIhI5kwmCITP7uJnFwsfHU17Tb7WToD4CEYmiyQTBp4BPA/uAveH0b5lZMXBbGmubdnQdgYhE0WROH91CMCjcWF6c2nKmt3jMdGMaEYmcyZw1VAR8DjgHKBpe7u6/k8a6pqVE3OjtV4tARKJlMoeG/oXgLKEPEdyRbA7Qmc6ipiudNSQiUTSZIFjs7n8JdLv7fcCvAeelt6zpKW7oymIRiZzJBEF/+HzIzM4FKoGmtFU0jcVjGoZaRKJnMheU3WNm1cCXCO4nUAb8ZVqrmqY01pCIRNGEQWBmMaDD3Q8CzwMLM1LVNBWPG/06fVREImbCQ0PuPoSuFZgyiZgxpBaBiETMZPoInjSzPzGzuWZWM/xIe2XTkK4sFpEomkwfwfD1AremLHN0mOikqY9ARKJoMlcWL8hEIflA1xGISBSd8NCQmZWY2ZfM7J5w/gwzuy79pU0/ahGISBRNpo/g20AfcHk43wL8j7RVNI3FY0b/oM4aEpFomUwQLHL3vyW8sMzdjxDcoEZOkloEIhJFkwmCvnDIaQcws0VAb1qrmqbicZ01JCLRM5kg+GvgMWCumd0PPA386WQ2bmZXm9lGM9tsZneMs84KM1tjZhvM7LnJFp6LCjTEhIhE0GTOGnrCzFYDlxIcEvqCu7ed6H1mFge+AVxJ0K+w0swedvfXU9apAv6B4HaY75jZzFPbjdwQDw8NuTtmOromItEwmfsRPAx8D3jY3btPYtuXAJvDG9tgZg8A1wOvp6zzSeBBd38HwN33ncT2c04iFvzyHxxyEnEFgYhEw2QODX0NeA/wupn90Mw+Ft6s5kQagR0p8y3hslRLgGoze9bMVpvZZ8bakJndbGarzGxVa2vrJD46muLhL3/1E4hIlJwwCNz9OXf/Q4Irie8BPk5w/+ITGetP3tG/ARPARQT3OPgQ8JdmtmSMGu5x92Z3b66rq5vER0dTaotARCQqJjPEBOFZQx8GbgCWA/dN4m0twNyU+TnArjHWaQsPOXWb2fPABcCmydSVa+KxIHfVIhCRKJnMlcXfB94A3k/Q+bvI3T8/iW2vBM4wswVmlgRuJLifQaqfAO8xs4SZlQDvCj9rWlKLQESiaDItgm8Dn3T3QQAze7eZfdLdb53oTe4+YGa3AY8DceBed99gZreEr9/l7m+Y2WPAOmAI+Ka7rz+dHYqyeGy4j0BXF4tIdEzm9NHHzGyZmX2C4NDQVuDByWzc3R8FHh217K5R818FvjrpinOYWgQiEkXjBkHYaXsj8AlgP/B9wNz9P2WotmlnpEUwqCAQkeiYqEXwJvAC8GF33wxgZrdnpKppavjaAbUIRCRKJuos/k1gD/CMmf2TmX0ADTZ3WnTWkIhE0bhB4O4/dvcbgKXAs8DtQL2Z/aOZXZWh+qYV9RGISBRN5oKybne/392vI7gWYA0w5gByMrHhPgLdk0BEomQyQ0yMcPcD7n63u78/XQVNZ2oRiEgUnVQQyOk5eh2BgkBEokNBkEEF8eCfWy0CEYkSBUEG6cpiEYkiBUEGqY9ARKJIQZBB6iMQkShSEGRQIrygbFBDTIhIhCgIMkgtAhGJIgVBBmmsIRGJIgVBBumsIRGJIgVBBiXD6wh6BxQEIhIdCoIMKiqIA9DTP5jlSkREjlIQZFBxUkEgItGjIMigokTwz93Tr0NDIhIdCoIMSsRjFMSNI2oRiEiEKAgyrCgR16EhEYkUBUGGFRYoCEQkWtIaBGZ2tZltNLPNZnbcXc3MbIWZtZvZmvDx5XTWEwXFyZj6CEQkUhLp2rCZxYFvAFcCLcBKM3vY3V8fteoL4W0w80JpMkFnz0C2yxARGZHOFsElwGZ33+LufcADwPVp/LycUFOa5NDhvmyXISIyIp1B0AjsSJlvCZeNdpmZrTWzn5nZOWmsJxKqS5McUBCISISk7dAQYGMsGz3a2ivAfHfvMrNrgYeAM47bkNnNwM0A8+bNm+IyM6umJMnBbgWBiERHOlsELcDclPk5wK7UFdy9w927wulHgQIzqx29IXe/x92b3b25rq4ujSWnX3VpkkNH+jUCqYhERjqDYCVwhpktMLMkcCPwcOoKZjbLzCycviSsZ38aa8q6uvJC3GFfZ0+2SxERAdJ4aMjdB8zsNuBxIA7c6+4bzOyW8PW7gI8Bf2BmA8AR4EZ3n9Z/Ki+uKwPgrb1dNFQWZ7kaEZH09hEMH+55dNSyu1Km7wTuTGcNUbOkPgiCN3Z38N4luX2YS0SmB11ZnGEzygo5s76cJ1/fm+1SREQABUFW3HDxXFZtP8jXn3qLHQcOq+NYRLIqrYeGZGyfvmw+v9q6n79/ahN//9QmAMoLE1QUFwSPogTVJUmqS5PMKA2ea0oLqCktpKYkSU1ZktqyJIWJeJb3RESmAwVBFhTEY9z1WxexYVcH61ra2dPRQ8eRfjp6+uk4MkDHkX62tHVxYHsfB7r7GK/BUFOaZGZ5IfUVRdRXBM8zK4qoH1lWRG1ZkkRcDT8RGZ+CIEvMjHMbKzm3sXLC9YaGnI6efg5094089nf30drZy96OHvZ29LKvs4c393TQ2tl7XGiYQW1ZIQ2VRcyqKAqeK4vD5yJmVxYzs6Jw5DaaIpJ/FAQRF4sZVSVJqkqSLDzBSUaDQ87+rl72doQh0RkExd72HnZ39LBtfzcvbdk/5qB3M0qTzKosGgmIhsrilOAI5odvtSki04uCYBqJx4yZ4eGh8xi/pdHVO8Ce9h72tPewu/1I8NwRzO881MOq7Qc5dLj/uPdVFhfQUHl8qyJ1WVmh/kuJ5Br91OahssIEi2eWsXhm2bjrHOkbZE9HSlCMBEcPezqO8NrOdtq6jh8zqbwwwaxjAqL42FZGZREVRQnCC8pFJAIUBDKm4mScBbWlLKgtHXed3oFB9nX0suvQkTA0jm1lbNzTSWtXL6OvFS9Jxo8ehqoY3bII5qtKChQWIhmiIJBTVpiIM7emhLk1JeOu0z84xL7OXva0HxkJil2HglbF7vYefvl2G3s7eo7r5C5MxI5rSRzt8A7mZ5QmicUUFiKnS0EgaVUQj9FYVUxj1fjjKg0MDtHW1XfsYaiRFsYRXt56gL0dPQyMSotkPEZ9ZSENFcWjOrqP9mHUlhUSV1iITEhBIFmXiMdG+hXGMzTktHX3Ht9fEbY01rYc4rENPfQNHHs/6HjMqC8vZFZlEY3VJSysLWVhXSmL6spYUFtKqTq3RRQEkhtiMWNmeREzy4s4f87Y67g7Bw/3s7v9CLsPDZ8JdfSQ1JodB3lk3a5j+iwaKotGgmHprArOmV3BmbPKdV2F5BUFgUwbZkZNaZKa0iTnzB779Nme/kG27e9mS2s3W1q72NLazdutXTz4yk66ercDQSticV0Z58yu4JzGSi5uqubshgpdoS3TloJA8kpRQZylsypYOqvimOXuzo4DR9iwq50NuzrYsKudFze38eCrO4HgTKfl86q5uKmGSxfWsHx+NQUKBpkmLNfuA9Pc3OyrVq3KdhmSJ/Z29PDy1gOs3HaAl7ceYOPeTtyhvCjBe5fU8f4zZ7LizDpmlBVmu1SRCZnZandvHvM1BYHI5LUf7uelLW38/M19PLOxldbOXuIx44rFtVy/bDZXnTNLV1dLJCkIRNJgaMhZv6udx9bv4SdrdrHz0BGKCmJ88Kx6PrKskfcuqSOZ0OEjiQYFgUiauTuvvHOQn6zZxSPrdnOgu4/qkgKuO382H7lwNsvnVetKackqBYFIBvUPDvHCW638+NVdPLFhD70DQ8yrKeGac2dx4bxqzmooZ2Z5kUZzlYyaKAh0MFNkihXEY7x/aT3vX1pPZ08/j2/Yy0Ov7uRbL25lYGjLyHrlhQnqKgqZWV5IY1UJy+ZVcXFTNWfWl6v1IBmlFoFIhvT0D7JhVwdbWrvY19lLa2dwU6F9Hb1s2989MprrnOpirjp7FlefO4vm+dUaT0mmhA4NiUScu9Ny8Ai/2NzGE6/v5cW32ugbHKK+opBrzm3g185v4KJ5CgU5dVkLAjO7Gvg6EAe+6e5fGWe9i4H/AG5w93+baJsKAskHXb0D/PzNffz7ul08s7GVvoGjoXDd+Q0sVyjIScpKEJhZHNgEXAm0ACuBT7j762Os9yTQA9yrIBA5VlfvAE+/sZd/X7ebZzcFoTCroohrzpvFdec3cOFchYKcWLY6iy8BNrv7lrCIB4DrgddHrfd54EfAxWmsRSRnlRUmuH5ZI9cva6Szp5+fv7mPR9bt5v5fvcO3f7GNWRVFXHteA1efO4vl86o0JpKctHQGQSOwI2W+BXhX6gpm1gh8FHg/EwSBmd0M3Awwb968KS9UJFeUFxUcEwpPvxGEwr/+x3bu/cVWyosSXLG4lhVn1vG+JTMnHNpbZFg6g2Csturo41D/B/gzdx+c6HQ5d78HuAeCQ0NTVaBILisvKuAjFzbykQuDUHjxrTae29TKsxtb+dn6PQAsnVXO+86s492LamluqqYkqTPG5Xjp/F/RAsxNmZ8D7Bq1TjPwQBgCtcC1Zjbg7g+lsS6Raae8qIBrzmvgmvMacHc27u3k2Y2tPLtxH996YSt3P7eFgrhxwZwqLls0g8sWzmD5/Grdd0GA9HYWJwg6iz8A7CToLP6ku28YZ/3vAI+os1hkanX3DrBq+0Feens/L23Zz2sthxjy4Fafy+ZVcemCYFjtC+dVU1lckO1yJU2y0lns7gNmdhvwOMHpo/e6+wYzuyV8/a50fbaIHFVamOB9S+p435I6ADp7+lm17SAvbdnPS2/v585nNjN8O+gl9WUsn1fN8vnVXDS/moW1pbrKOQ/ogjKRPNfdO8DaHYdYvf0gr7xzkNXbD9LRMwBAVUkBy+dVc8GcKs6fU8m5jZXUleveC7lIYw2JyLhKCxNcvriWyxfXAsHw2lvauli9/WAYDod4ZuO+kXs9N1QWcV5jJefPqeS8OVWc11hJTWkyi3sgp0tBICLHiMWMxTPLWTyznBsuDk7X7uodYMPOdl7b2c66lnbW72znidf3jrynsaqY8+dUcs7sCs5qqGBpQwWzK4t0WClHKAhE5ITKChO8a+EM3rVwxsiyjp5+1u8MQmFdSxASw6etAlQWF7B0VjlnNVRwdkMQEGfUl+lMpQhSEIjIKakoKuDyRbVcvqh2ZFlnTz8b93Tyxu4OXt/dyZt7OvjBqh0c7hsEIB4zFtaWsrShgrMayjlrVhAOjVXFaj1kkYJARKZMeVEBzU01NDfVjCwbGnK2HzjMG7s7Rh6vbD/IT9cevayoNBlncX05S2aWsaS+nDPqg+cGHV7KCJ01JCJZ0X64n037Otm0t5O39naxaW8nm/Z20dbVO7JOWWGCxTPLWFI/HBDlLKkvY1aFAuJk6awhEYmcypICLm6q4eKU1gPAwe6+IBT2dbE5DIefv7mPH6xqGVmnvCjBGTPLWFRXxqKZZSysLWXRzDLm1ZRQoEH3TppaBCKSEw6EAfFWGA5v7etkS2s3+zqPtiASMWP+jJLjAmJRXVneXzWtFoGI5Lya0iSXLpzBpSlnLkFw9tKW1m7e3tfF263Dj26e2biP/sGjf+jWlhWyqO5oMCysK2VxXRmzq4qJ5/n9HBQEIpLTKooKWDa3imVzq45ZPjA4xI6DR44LiEdf282hw/0j6xUmYiyoLWVhXSkLaktpmhFMN80opaY0mRd9EQoCEZmWEvHgF/yC2lI+SP0xrx3o7guCIQyJzfu6eGN3J49v2Mvg0NFWREVRYmQbTeHz8HRF0fQ51KQgEJG8U1OapKb0+I7q/sEhWg4eYWtbF1vbDrO1rYttbYdZue0gP1m7i9Qu1dqy5EgLYkFdKQvC56YZpTl30ZyCQEQkVJDSihitp3+Q7fsPs7Wtm61t3WwLn5/d1MoPV7ccs+7syqJjWhDDrYi51SUkE9E7q0lBICIyCUUFcc6cVc6Zs8qPe62zp/+4kNjS1s0j63bTfuRof0Q8ZsypLmb+jFKaZpQc8zy3ppjCRHZaEgoCEZHTVF5UwLmNwTDdox3s7mPr/m62tnazbX832/YfZltbN69uP0hn78DIejGD2VXFNM0oZf6MkqPPtaXMqylJ6+EmBYGISBpVlyapLk2yfF71McvdnYOH+4NwaAsCYnsYFP8+6swmM2ioKOJ3rljA775n4ZTXqCAQEckCMws7rY8PCYBDh/uOhkNb8JyumwIpCEREIqiqJMmykuRx10ekQ/S6r0VEJKMUBCIieU5BICKS5xQEIiJ5TkEgIpLnFAQiInlOQSAikucUBCIieS7nblVpZq3A9lN8ey3QNoXlZJP2JZqmy75Ml/0A7cuw+e5eN9YLORcEp8PMVo13z85co32JpumyL9NlP0D7Mhk6NCQikucUBCIieS7fguCebBcwhbQv0TRd9mW67AdoX04or/oIRETkePnWIhARkVEUBCIieS5vgsDMrjazjWa22czuyHY9J2Jm28zsNTNbY2arwmU1Zvakmb0VPlenrP/n4b5tNLMPZa9yMLN7zWyfma1PWXbStZvZReG/wWYz+79mZhHZl782s53hd7PGzK6N+r6Y2Vwze8bM3jCzDWb2hXB5zn0vE+xLLn4vRWb2spmtDfflv4bLM/u9uPu0fwBx4G1gIZAE1gJnZ7uuE9S8DagdtexvgTvC6TuAvwmnzw73qRBYEO5rPIu1vxdYDqw/ndqBl4HLAAN+BlwTkX35a+BPxlg3svsCNADLw+lyYFNYb859LxPsSy5+LwaUhdMFwK+ASzP9veRLi+ASYLO7b3H3PuAB4Pos13QqrgfuC6fvAz6SsvwBd+91963AZoJ9zgp3fx44MGrxSdVuZg1Ahbu/5MH/8n9OeU/GjLMv44nsvrj7bnd/JZzuBN4AGsnB72WCfRlPlPfF3b0rnC0IH06Gv5d8CYJGYEfKfAsT/8eJAgeeMLPVZnZzuKze3XdD8MMAzAyX58L+nWztjeH06OVRcZuZrQsPHQ0323NiX8ysCbiQ4K/PnP5eRu0L5OD3YmZxM1sD7AOedPeMfy/5EgRjHSuL+nmz73b35cA1wK1m9t4J1s3F/Rs2Xu1R3qd/BBYBy4DdwNfC5ZHfFzMrA34E/Gd375ho1TGWRX1fcvJ7cfdBd18GzCH46/7cCVZPy77kSxC0AHNT5ucAu7JUy6S4+67weR/wY4JDPXvDJiDh875w9VzYv5OtvSWcHr0869x9b/jDOwT8E0cPw0V6X8ysgOAX5/3u/mC4OCe/l7H2JVe/l2Hufgh4FriaDH8v+RIEK4EzzGyBmSWBG4GHs1zTuMys1MzKh6eBq4D1BDX/drjabwM/CacfBm40s0IzWwCcQdBxFCUnVXvYHO40s0vDsx8+k/KerBr+AQ19lOC7gQjvS/i53wLecPe/S3kp576X8fYlR7+XOjOrCqeLgQ8Cb5Lp7yWTPeTZfADXEpxd8DbwxWzXc4JaFxKcGbAW2DBcLzADeBp4K3yuSXnPF8N920gWzq4ZVf/3CJrm/QR/qXzuVGoHmgl+mN8G7iS8Ej4C+/IvwGvAuvAHsyHq+wJcQXCoYB2wJnxcm4vfywT7kovfy/nAq2HN64Evh8sz+r1oiAkRkTyXL4eGRERkHAoCEZE8pyAQEclzCgIRkTynIBARyXMKAskJZtYVPjeZ2SeneNt/MWr+l1O5/almZp81szuzXYdMHwoCyTVNwEkFgZnFT7DKMUHg7pefZE05ZRL/HpJnFASSa74CvCccb/72cMCur5rZynCwsd8HMLMVFoxZ/12Ci4wws4fCQfw2DA/kZ2ZfAYrD7d0fLhtufVi47fXhOO83pGz7WTP7NzN708zuH2vs93Cdv7FgvPlNZvaecPkxf9Gb2SNmtmL4s8P3rDazp8zsknA7W8zs11M2P9fMHrNgTPq/StnWb4Wft8bM7h7+pR9u97+Z2a8IhioWOSqTV9HpocepPoCu8HkF8EjK8puBL4XThcAqgnHaVwDdwIKUdWvC52KCKzBnpG57jM/6TeBJgvtZ1APvEIyFvwJoJxjPJQa8BFwxRs3PAl8Lp68FngqnPwvcmbLeI8CKcNoJrxYlGGPqCYKhiS8A1qS8fzfB1afD+9IMnAX8FCgI1/sH4DMp2/14tr9HPaL5SJx0cohEy1XA+Wb2sXC+kmD8lT6CMVi2pqz7R2b20XB6brje/gm2fQXwPXcfJBgE7DngYqAj3HYLgAVDCDcBL46xjeHB3VaH65xIH/BYOP0a0Ovu/Wb22qj3P+nu+8PPfzCsdQC4CFgZNlCKOTpY2SDBIG0ix1EQSK4z4PPu/vgxC4NDLd2j5j8IXObuh83sWaBoEtseT2/K9CDj/yz1jrHOAMcelk2to9/dh8d9GRp+v7sPmVnqZ4weG2Z4KOL73P3Px6ijJww0keOoj0ByTSfB7QmHPQ78QTgsMWa2JByxdbRK4GAYAksJbgc4rH/4/aM8D9wQ9kPUEdy2cipGdd0GLDOzmJnN5dTuJnelBfe1LSa4E9UvCAYn+5iZzYSR+97On4J6ZZpTi0ByzTpgwMzWAt8Bvk5wyOSVsMO2lbFv0fcYcIuZrSMYtfE/Ul67B1hnZq+4+6dSlv+YoGN1LcFf3H/q7nvCIDkdvwC2Ehz6WQ+8cgrbeJFgtM3FwHfdfRWAmX2J4M52MYIRU28Ftp9mvTLNafRREZE8p0NDIiJ5TkEgIpLnFAQiInlOQSAikucUBCIieU5BICKS5xQEIiJ57v8Dzv4Xis0hNAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the avg_cost_func\n",
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[13.7 10.4  5.8 16.7 12.5 12.  13.4 13.4 11.3 10.4 16.4 15.8  7.7  4.2\n",
      "  9.4 15.  10.7  9.7 11.1 10.  14.5  8.6 11.  10.3 13.1 13.5 12.1 16.\n",
      "  8.3 14.4 14.7 12.4 15.   9.  13.3 14.7 10.7 10.  10.  10.4 10.3  8.4\n",
      " 11.3 10.5 14.4 11.7 10.4  8.  12.3 11.   6.4 10.  12.1  9.3 10.3  6.9\n",
      " 11.  10.7 12.7 14.4 10.7 12.3 15.8 10.  14.4  8.8 14.3 12.  11.6 13.3\n",
      " 14.  13.  15.   8.4 13.  11.1 14.1 14.7 13.3 17.   8.8 10.3 10.6 12.4\n",
      "  9.7 12.  18.  12.2 12.4  9.7 15.4 13.  11.7 17.4  9.1 10.4 10.  10.7\n",
      " 17.7 11.1 11.1  9.  11.  16.4  9.   9.  14.7 12.1 13.7 15.4 11.  11.\n",
      " 13.3 11.8 11.4 12.1 14.4 13.3 14.7  8.7  8.1 14.1 15.8  7.   7.4 10.\n",
      " 17.7 16.   9.4 14.1  9.1 11.  13.7 11.3 12.4 10.   8.6  8.7 14.  13.\n",
      "  8.8 12.9 10.  10.1 13.  10.3 12.8 14.   8.7 10.1 11.7 13.3 15.5 12.7\n",
      "  4.2 13.  17.3 16.  12.1 10.7  9.7 12.7 11.8  9.4 10.7 12.7 10.7 15.7\n",
      " 13.7 16.4  8.  10.7 15.5  3.6 11.3 11.1 12.4 15.7 14.4 15.  10.7  9.7\n",
      " 10.4 12.5 11.4 17.6 12.7 10.7  9.1  7.   9.8  8.4  9.4  8.4 13.3 10.3\n",
      " 10.  17.7  7.3 13.3 18.  17.  10.1 13.1 10.   7.7 12.1 10.  13.7  9.3\n",
      " 10.3 15.7 12.3 11.7  9.3 15.  12.3  8.7 10.1  7.3 15.7 18.   7.3 14.7\n",
      "  8.7 13.1  6.5 15.7 11.3 10.1  8.8 10.4 12.7  8.6  7.7 11.4  9.7 13.\n",
      " 10.4 18.  12.7 14.1 16.  10.7 14.6 12.4 10.  17.1 10.  16.3 15.1 13.\n",
      " 13.7 13.1 11.  14.  14.8 11.   1.5  9.7]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-ceb52cde6aba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Prediction accuracy is {}%'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_structure = [26, 30, 3]\n",
    "    \n",
    "# train the NN\n",
    "W, b, avg_cost_func = train_rigde_nn(nn_structure, X_train, y_v_train, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "print('Prediction accuracy is {}%'.format(accuracy_score(y_test, y_pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
