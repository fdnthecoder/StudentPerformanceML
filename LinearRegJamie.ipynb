{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-90bdcb20ed23>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-90bdcb20ed23>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    * Analysis of student performances\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# STUDENT PERFORMANCES\n",
    "## Machine Learning project\n",
    "## Team: Amadou and Jamie\n",
    "\n",
    "* Analysis of student performances\n",
    "* Features: 33 \n",
    "* Data: 649\n",
    "\n",
    "There are 2 different csv files in the data folder. One (student-port.csv) being the data set of the students that took the portugese language course and another (student-mat.csv) of the students that are taking the math course. There are 382 students that are taking both courses. \n",
    "\n",
    "More information about the dataset is in the data folder, labeled student.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries to be used:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # It is important in neural networks to scale the date\n",
    "from sklearn.model_selection import train_test_split  # The standard - train/test to prevent overfitting and choose hyperparameters\n",
    "from sklearn.metrics import accuracy_score # \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data\\student-por.csv\",sep=\";\") #read file from different directory\n",
    "df2 = pd.read_csv(\"data\\student-mat.csv\", sep = \";\")\n",
    "print(df1)\n",
    "#df1.to_csv(\"port.csv\") # made in to a csv after being made in to a table - easier to read compared to original excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data accordingly\n",
    "X = df1.iloc[:, :30]\n",
    "y = df1.iloc[:, 32:]\n",
    "X.dropna()\n",
    "y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixingfile(X):\n",
    "    switch = {0: (\"GP\", \"MS\"), 1: (\"F\", \"M\"), 3: (\"U\", \"R\"), 4: (\"LE3\", \"GT3\"), 5:(\"T\", \"A\"), 15:(\"yes\",\"no\"), 16:(\"yes\",\"no\"),\n",
    "             17:(\"yes\",\"no\"), 18:(\"yes\",\"no\"), 19:(\"yes\",\"no\"), 20:(\"yes\",\"no\"), 21:(\"yes\",\"no\"), 22:(\"yes\",\"no\")}\n",
    "    #ignore = [\"age\", \"Medu\", \"Fedu\",\"Mjob\", \"Fjob\", 'reason', 'guardian','traveltime', 'studytime',\n",
    "    #       'failures']\n",
    "    #print(X.columns)\n",
    "    #print(X.iloc[0,:])\n",
    "    for column in range(len(X.columns)):\n",
    "        if column not in switch:\n",
    "            continue\n",
    "        for i in range(len(X.iloc[:,column])):\n",
    "           #print(X.iloc[i, column] == \"U\",X.iloc[i, column], switch[column])\n",
    "            if X.iloc[i,column] == switch[column][0]:\n",
    "                #print(X.iloc[i, column], switch[column][0])\n",
    "                X.iloc[i,column] = 1\n",
    "            elif X.iloc[i, column] == switch[column][1]:\n",
    "                X.iloc[i,column] = 0\n",
    "    X.drop([\"Mjob\", \"Fjob\", \"reason\", \"guardian\"], axis = 1, inplace=True) #Remove the ones with more than 1 and 0 answers\n",
    "    print(X.shape)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fixed = fixingfile(X)\n",
    "y = np.array(y) #changed to array to be easier to work with\n",
    "X = np.array(X_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM here on out the markdown split up which model. Add cells according to which mark down. Here is the order\n",
    "## 1. Linear Regression\n",
    "## 2. Neutral Network \n",
    "## 3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping y to 2d\n",
    "y_2d = y.reshape(y.shape[0], 1)\n",
    "print(\"Checking y_2d is in 2d:\", y_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = y.shape[0]\n",
    "print(\"Number of rows:\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the column of ones infront of x\n",
    "ones = np.ones((N, 1))\n",
    "X_1 = np.hstack((ones, X))\n",
    "print(\"X_1 shape:\", X_1)\n",
    "print(\"X_1 with ones: \", X_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X_1, y_2d, w, N):\n",
    "    # Write your code in place of ellipsis. Cost can be calculated using a single line of code.\n",
    "    # Remember w is a vector here.\n",
    "    \n",
    "    # TODO Q07 - Taken from hw\n",
    "    # Write the cost function\n",
    "    #ISSUES: X AND Y ARE NOW 2D ARRAYS\n",
    "    cost = sum((y_2d- (np.dot(X_1, w)))**2)/(2*N)\n",
    "    \n",
    "    return cost[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_1, y_2d, learning_rate, w, N, num_iters):\n",
    "    # In place of ellipsis, write the updated value of w0 in temp0 and of w1 in temp1\n",
    "    # TODO Q08\n",
    "    # Finish the gradient descent function\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        # derivative vector is given by : X_train.Transpose *  (( X_train * w)- y ) \n",
    "        slope = np.dot(X_1, w)\n",
    "        der_vector = np.dot(X_1.T,(slope - y_2d))\n",
    "        w = w - (learning_rate * (1/N)) * der_vector\n",
    "       \n",
    "        \n",
    "        if(i % 100 == 0):\n",
    "            # In place of ellipsis, call the cost you just coded above\n",
    "            cost = compute_cost(X_1, y_2d, w, N)\n",
    "            # You can uncomment print statements below to see how cost changes, \n",
    "            # but please make sure you put prints in comments before submission\n",
    "            #print(\"Cost\")\n",
    "            #print(cost)\n",
    "             \n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_testcase = np.zeros((X.shape[1]+1,1))\n",
    "g = gradient_descent(X_1, y_2d, 0.0049, w_testcase, N, 1000)\n",
    "#print(g)\n",
    "print(\"g[0]: \", g[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0049\n",
    "num_iters = 100\n",
    "results = multiple_linear_reg_model_gda(X_1, y_2d, learning_rate, N, num_iters)\n",
    "print(\"w: \", results[0], \"\\ninitial cost: \", results[1], \"\\nfinal cost: \", results[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f1be54ba100e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Split the data into training and test set.  60% training and %40 test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
